# DadAI â€“ An LLM-based assistant for new dads ğŸ¤–ğŸ‘¶

**DadAI** is an open-source project built to support new fathers during pregnancy and early parenthood.  
The idea is simple: provide emotionally intelligent, practical guidance powered by LLMs â€” and built on **Mistral 7B**.

## ğŸš€ Why DadAI?

Most resources around parenting are either mother-centric or scattered across forums.  
As a first-time dad, I realized how hard it can be to find support that's both practical and emotionally relevant â€” and I wanted to make things easier for other future dads.  

DadAI aims to provide a clear, AI-driven interface that supports:
- Emotional support during pregnancy
- Concrete actions and reminders
- Guidance on sleep, communication, and partner well-being

## ğŸ§  Tech Stack

- [x] Mistral 7B (quantized with GGUF)
- [x] LoRA fine-tuning with QLoRA
- [x] Python (Transformers, PEFT, Datasets)
- [x] Deployment via [LocalAI](https://github.com/go-skynet/LocalAI)
- [ ] Web interface (optional â€“ future)

## ğŸ“‚ Project Structure

```
dadAI/
â”œâ”€â”€ data/                       # Datasets (raw, cleaned, formatted)
â”‚   â”œâ”€â”€ reddit_dataset.jsonl
â”‚   â”œâ”€â”€ cleaned_dataset.jsonl
â”‚   â””â”€â”€ formatted_dataset.jsonl
â”œâ”€â”€ lora_finetune/             # Fine-tuning and inference
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ merge_lora.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â”œâ”€â”€ inference_batch.py
â”‚   â”œâ”€â”€ prepare_dataset.py
â”‚   â””â”€â”€ convert_to_gguf.py
â”œâ”€â”€ scripts/                   # Data collection, formatting, tests
â”‚   â”œâ”€â”€ collect_reddit_data.py
â”‚   â”œâ”€â”€ format_reddit_data.py
â”‚   â”œâ”€â”€ clean_dataset.py
â”‚   â”œâ”€â”€ check_dataset_format.py
â”‚   â”œâ”€â”€ test_reddit_connection.py
â”‚   â””â”€â”€ show_random_sample.py
â”œâ”€â”€ models/                    # LocalAI-compatible GGUF models
â”œâ”€â”€ tests/                     # Prompt examples, screenshots
â”‚   â””â”€â”€ Prompt dadAI.png
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                       # PRAW credentials
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ’¬ Status

| Phase | Description | Status |
|-------|-------------|--------|
| 1. Setup | Conda, PRAW, Mistral, VS Code | âœ… Done |
| 2. Data | Reddit scraping + cleaning + format | âœ… Done (400+ posts) |
| 3. Fine-tune | LoRA (QLoRA) with GPTQ Mistral | âœ… Done |
| 4. Inference | Working with corrected weights | âœ… Done |
| 5. Merge & Deploy | GGUF export + LocalAI run | ğŸ”œ Next |

Fine-tuning and inference will be tested on [RunPod](https://www.runpod.io/) using QLoRA and Mistral 7B.

## ğŸ“Œ Goals

- Train an assistant on real parenting data (Reddit, BabyCenter)
- Optimize responses via QLoRA and test performance locally
- Package the assistant behind a simple OpenAI-compatible API

## ğŸ§ª Local Inference with Mistral 7B (via LocalAI)

- **Model:** TheBloke/Mistral-7B-Instruct-v0.1-GPTQ
- **Quantization:** GPTQ 4-bit
- **Fine-Tuning:** QLoRA + PEFT (LoRA adapters)
- **Data:** 400+ high-quality Reddit pairs (Instruction/Response)
- **Output:** LoRA weights (~100MB) + merged model planned

- `inference.py`: basic text generation
- `inference_batch.py`: batched inputs
- `dadAI_inference_test.ipynb`: sandbox notebook

You can run DadAI locally using [LocalAI](https://github.com/go-skynet/LocalAI), an open-source alternative to the OpenAI API.

This setup uses the **Mistral 7B Instruct model** in GGUF format and exposes a local `/v1/chat/completions` endpoint, fully compatible with OpenAIâ€™s API.

### ğŸ§  1. Download the model

We recommend downloading the `Q4_K_M` quantized version from [TheBloke's Hugging Face page](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF):

```bash
wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf -P localai/models/
```

> âš ï¸ This file is **not included in the repo** (see `localai/models/README.md` for details)

---

More to come soon:
- Fine-tuning instructions (QLoRA)
- LangChain agent with memory
- Streamlit chatbot

## ğŸ‘¤ Author

**BenoÃ®t Rossignol**  
ğŸ“ Geneva  
ğŸ’¼ Solution Architect  
ğŸ§  AI & PreSales Leader