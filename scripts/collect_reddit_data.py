import praw
import os
import json
from datetime import datetime
from tqdm import tqdm
import time
from dotenv import load_dotenv
from pathlib import Path

# ğŸ“‚ Charge les variables d'environnement
load_dotenv()

# ğŸ” Connexion Reddit via PRAW
reddit = praw.Reddit(
    client_id=os.getenv("REDDIT_CLIENT_ID"),
    client_secret=os.getenv("REDDIT_CLIENT_SECRET"),
    user_agent=os.getenv("REDDIT_USER_AGENT"),
    username=os.getenv("REDDIT_USERNAME"),
    password=os.getenv("REDDIT_PASSWORD")
)

# ğŸ”§ ParamÃ¨tres
subreddits = ["NewDads", "Daddit", "BabyBumps", "Parenting"]
max_posts_per_sub = 250
min_score = 10
output_file = Path(__file__).parent.parent / "data" / "reddit_dataset.jsonl"
# output_file = "reddit_dataset.jsonl"
max_years_back = 10

def get_top_posts(subreddit_name, limit_per_year, max_years=10):
    """ğŸ” RÃ©cupÃ¨re les top posts valides dâ€™un subreddit, annÃ©e par annÃ©e"""
    valid_posts = []
    current_year = datetime.now().year
    attempts = 0

    for year in range(current_year, current_year - max_years, -1):
        if len(valid_posts) >= limit_per_year:
            break

        try:
            print(f"ğŸ” {subreddit_name} - AnnÃ©e {year}...")
            subreddit = reddit.subreddit(subreddit_name)
            top_posts = subreddit.top(time_filter="year", limit=100)

            for post in top_posts:
                # Skip les posts dâ€™autres annÃ©es
                post_year = datetime.fromtimestamp(post.created_utc).year
                if post_year != year:
                    continue

                # Skip si dÃ©jÃ  assez de posts
                if len(valid_posts) >= limit_per_year:
                    break

                # VÃ©rifie la prÃ©sence de commentaires
                try:
                    post.comments.replace_more(limit=0)
                    top_comment = post.comments[0] if post.comments else None
                    if top_comment is None or len(top_comment.body.strip()) == 0:
                        continue
                except Exception:
                    continue

                # Enregistre le post
                valid_posts.append({
                    "subreddit": subreddit_name,
                    "year": year,
                    "title": post.title,
                    "selftext": post.selftext,
                    "score": post.score,
                    "comment": top_comment.body.strip(),
                    "permalink": post.permalink
                })

        except Exception as e:
            print(f"âš ï¸  Erreur sur {subreddit_name} ({year}) : {e}")
            time.sleep(2)  # petite pause en cas d'erreur Reddit

    return valid_posts

# ğŸ§  Lancement
all_data = []
print("ğŸ“¡ Lancement de la collecte Reddit...\n")

for subreddit in tqdm(subreddits, desc="ğŸ” Subreddits"):
    posts = get_top_posts(subreddit, limit_per_year=max_posts_per_sub, max_years=max_years_back)
    print(f"âœ… {subreddit} : {len(posts)} posts collectÃ©s\n")
    all_data.extend(posts)

# ğŸ’¾ Sauvegarde en JSONL
with open(output_file, "w") as f:
    for item in all_data:
        f.write(json.dumps(item) + "\n")

print(f"\nğŸ‰ TerminÃ© ! {len(all_data)} posts sauvegardÃ©s dans {output_file}")